{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(top_genes): 100\n",
      "M.shape: (100, 51)\n",
      "Number of nodes: 51\n",
      "Done creating PAN graph!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "NUM_GENE = 100 #number of genes to be used\n",
    "# get all_genes: all genes appeared in all the ontologies\n",
    "bf = pd.read_csv('input_data/hgncToKEGG.csv')\n",
    "KEGG_genes = dict(zip(bf['symbol'], bf['path'] ))\n",
    "bf = pd.read_csv('input_data/hgncToHPO.csv')\n",
    "HPO_genes = dict(zip(bf['gene'], bf['pathway'] ))\n",
    "bf = pd.read_csv('input_data/hgncToDO.csv')\n",
    "DO_genes = dict(zip(bf['gene'], bf['pathway'] ))\n",
    "all_genes = list(set(KEGG_genes.keys()).intersection(set(HPO_genes.keys())).intersection(set(DO_genes.keys()))) \n",
    "\n",
    "# get gene_go_all: dictionary of gene - KEGG_ontology for all genes appeared in KEGG \n",
    "# we could use other ontologies here, e.g., HPO or DO, instead of KEGG\n",
    "df = pd.read_csv('input_data/hgncToKEGG.csv')\n",
    "gene_go_all = dict(zip(df['symbol'], df['path'] ))\n",
    "df = pd.read_csv('input_data/UK207.csv')\n",
    "# filter out data points not having the label\n",
    "df = df[ df['event'].notnull()]\n",
    "df = df.dropna(axis=1, how='any')\n",
    "# only consider genes appeared in all the three ontologies, making them comparable\n",
    "genes = list(set(all_genes).intersection(set(df.columns)))\n",
    "sel = VarianceThreshold()\n",
    "sel.fit(df[genes].values)\n",
    "score = sel.variances_\n",
    "# selecting NUM_GENE genes, stored in top_genes\n",
    "idx = np.argsort(score, 0)[::-1][:NUM_GENE]\n",
    "top_genes = [ genes[e] for e in idx ]\n",
    "print('len(top_genes):', len(top_genes))\n",
    "with open('output_data/top_genes.txt','w') as f:\n",
    "    f.write('\\n'.join(top_genes))\n",
    "\n",
    "# get gene_go: dictionary of gene - KEGG_ontology for the top genes\n",
    "# and its reverse, go_gene, a dictionary of KEGG_ontology - gene\n",
    "gene_go = {}\n",
    "for gene in gene_go_all:\n",
    "    if gene in top_genes:\n",
    "        gene_go[gene] = gene_go_all[gene]\n",
    "go_gene = {}\n",
    "for gene in gene_go:\n",
    "    goes = gene_go[gene].split('|')\n",
    "    for go in goes:\n",
    "        try:\n",
    "            go_gene[go] += [gene]\n",
    "        except:\n",
    "            go_gene[go] = [gene]\n",
    "\n",
    "# get gene expression and the label for top genes and store it in gene_condition\n",
    "gene_condition = df[ top_genes + ['event'] ]\n",
    "gene_condition['event'] = gene_condition['event'].apply(int)\n",
    "gene_condition.columns = top_genes + [ 'condition' ]\n",
    "gene_condition.to_csv('output_data/gene_condition.csv',index=None)\n",
    "# store X and y separately\n",
    "non_graph = gene_condition[ top_genes ]\n",
    "non_graph.to_csv('output_data/non_graph.csv',index=None,header=None)\n",
    "yy = gene_condition['condition'].values.astype(int)\n",
    "with open('output_data/y.txt','w') as f:\n",
    "    f.write('\\n'.join(map(str,yy)))\n",
    "# gene expression: will be used as input for LIONESS    \n",
    "exp = non_graph.T\n",
    "exp.to_csv('output_data/gene_expression.txt',header=None,sep='\\t')    \n",
    "\n",
    "# create ten-fold splits to be used for all models\n",
    "for seed in range(10):\n",
    "    idx_0 = np.where( yy==0 )[0].flatten()\n",
    "    idx_1 = np.where( yy==1 )[0].flatten()\n",
    "    random.Random(seed).shuffle(idx_0)\n",
    "    idx_0 = idx_0[:len(idx_1)]\n",
    "    idx = list(idx_0) + list(idx_1)\n",
    "    random.Random(seed).shuffle(idx)\n",
    "    y = yy[idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(idx, y,test_size=0.3,random_state=0,stratify=y)\n",
    "    directory = '10fold_idx' \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(directory + '/train_idx-' + str(seed+1) + '.txt', 'w') as f:\n",
    "        f.write('\\n'.join(map(str,X_train)))\n",
    "    with open(directory + '/test_idx-' + str(seed+1) + '.txt', 'w') as f:\n",
    "        f.write('\\n'.join(map(str,X_test)))\n",
    "\n",
    "\n",
    "# create PAN graphs for non_graph data where the link is built from the relation of KEGG ontologies among selected genes\n",
    "gene_list = list(gene_go.keys())\n",
    "gene_list.sort()\n",
    "gene_idx = {gene_list[i]:i for i in range(len(gene_list))}\n",
    "go_list = []\n",
    "for e in gene_go:\n",
    "    go_list += gene_go[e].split('|')\n",
    "go_list = list(set(go_list))\n",
    "go_list.sort()\n",
    "go_idx = {go_list[i]:i for i in range(len(go_list))}\n",
    "\n",
    "M = np.zeros((len(gene_idx),len(go_idx)))\n",
    "print('M.shape:', M.shape)\n",
    "for gene in gene_idx:\n",
    "    g_idx = gene_idx[gene]\n",
    "    goes = gene_go[gene].split('|')\n",
    "    for go in goes:\n",
    "        M[g_idx][go_idx[go]] = 1        \n",
    "\n",
    "NUM_COL = len(go_idx)\n",
    "exp = non_graph[gene_list].values\n",
    "# create continuous graph\n",
    "with open('output_data/pan_graph.csv','w') as f:\n",
    "    ls = [] \n",
    "    for i in range(NUM_COL-1):\n",
    "        for j in range(i+1,NUM_COL):\n",
    "            ls += [ str(i) + '_' + str(j) ]\n",
    "    f.write(','.join(ls) + '\\n')\n",
    "    count = 0\n",
    "    for e in exp:\n",
    "        ls = [] \n",
    "        m = np.multiply(M,np.reshape(e, (len(e),1)))\n",
    "        m = m.T\n",
    "        D = scipy.spatial.distance.cdist(m,m)\n",
    "        for i in range(NUM_COL-1):\n",
    "            for j in range(i+1,NUM_COL):\n",
    "                dst = D[i,j]\n",
    "                if dst==0:\n",
    "                    dst = 1e-6\n",
    "                ls += [ round(1/dst,4)  ]\n",
    "        f.write(','.join(map(str,ls)) + '\\n') \n",
    "        \n",
    "NUM_EDGE = 200 # number of edges for adjacency graph\n",
    "# turn graphs with continous weights to adjacency graph\n",
    "GG = to_adjacency_G('output_data/pan_graph.csv',NUM_EDGE)\n",
    "# get features for this adjacency graph\n",
    "feats = get_closeness_centrality(GG)\n",
    "# store the feature in 'pan_graph_feature.csv'\n",
    "with open('output_data/pan_graph_feature.csv', 'w') as f:\n",
    "    for e in feats:\n",
    "        f.write(','.join(map(str,e)) + '\\n')        \n",
    "        \n",
    "print('Done creating PAN graph!')         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
